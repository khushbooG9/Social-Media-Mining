{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "community detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushbooG9/Social-Media-Mining/blob/master/community_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHmRmgs6RaZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collabrated with Shakti Priya and Dinesh\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from bokeh.io import show, output_notebook\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.models.annotations import LabelSet\n",
        "from bokeh.models.graphs import from_networkx\n",
        "import matplotlib.pyplot as plt\n",
        "# Though the following import is not directly being used, it is required\n",
        "# for 3D projection to work\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3prQmwxSBUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7h2ElCjRaaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import networkx as nx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7GF98i2RaaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f6a9e48b-c64c-452e-d9f3-290a83621991"
      },
      "source": [
        "\n",
        "!pip install twitter"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e2/f602e3f584503f03e0389491b251464f8ecfe2596ac86e6b9068fe7419d3/twitter-1.18.0-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hInstalling collected packages: twitter\n",
            "Successfully installed twitter-1.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH3kvktFRaaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from twitter import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBeir3auRaaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To make it more readable, lets store\n",
        "# the OAuth credentials in strings first.\n",
        "CONSUMER_KEY = '############'\n",
        "CONSUMER_SECRET = '############'\n",
        "OAUTH_TOKEN = '\t#################'\n",
        "OAUTH_TOKEN_SECRET = '###########################'\n",
        "    \n",
        "# Then, we store the OAuth object in \"auth\"\n",
        "auth = OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
        "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
        "\n",
        "# Notice that there are four tokens - you need to create these in the\n",
        "# Twitter Apps dashboard after you have created your own \"app\".\n",
        "\n",
        "# We now create the twitter search object.\n",
        "t = Twitter(auth=auth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvyUYQtbRaaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import time\n",
        "from twitter.api import TwitterHTTPError\n",
        "from urllib.error import URLError\n",
        "from http.client import BadStatusLine\n",
        "\n",
        "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw):\n",
        "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
        "    # value for wait_period if the problem is a 500 level error. Block until the\n",
        "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
        "    # for 401 and 404 errors, which requires special handling by the caller.\n",
        "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
        "        if wait_period > 3600: # Seconds\n",
        "            print('Too many retries. Quitting.', file=sys.stderr)\n",
        "            raise e\n",
        "        if e.e.code == 401:\n",
        "            return None\n",
        "        elif e.e.code == 404:\n",
        "            print('Encountered 404 Error (Not Found)', file=sys.stderr)\n",
        "            return None\n",
        "        elif e.e.code == 429:\n",
        "            print('Encountered 429 Error (Rate Limit Exceeded)', file=sys.stderr)\n",
        "            if sleep_when_rate_limited:\n",
        "                print(\"Retrying in 15 minutes...ZzZ...\", file=sys.stderr)\n",
        "                sys.stderr.flush()\n",
        "                time.sleep(60*15 + 5)\n",
        "                print('...ZzZ...Awake now and trying again.', file=sys.stderr)\n",
        "                return 2\n",
        "            else:\n",
        "                raise e # Caller must handle the rate limiting issue\n",
        "        elif e.e.code in (500, 502, 503, 504):\n",
        "            print('Encountered %i Error. Retrying in %i seconds' % (e.e.code, wait_period), file=sys.stderr)\n",
        "            time.sleep(wait_period)\n",
        "            wait_period *= 1.5\n",
        "            return wait_period\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "    # End of nested helper function\n",
        "\n",
        "    wait_period = 2\n",
        "    error_count = 0\n",
        "    while True:\n",
        "        try:\n",
        "            return twitter_api_func(*args, **kw)\n",
        "        except TwitterHTTPError as e:\n",
        "            error_count = 0\n",
        "            wait_period = handle_twitter_http_error(e, wait_period)\n",
        "            if wait_period is None:\n",
        "                return\n",
        "        except URLError as e:\n",
        "            error_count += 1\n",
        "            print(\"URLError encountered. Continuing.\", file=sys.stderr)\n",
        "            if error_count > max_errors:\n",
        "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
        "                raise\n",
        "        except BadStatusLine as e:\n",
        "            error_count += 1\n",
        "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
        "            if error_count > max_errors:\n",
        "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
        "                raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7lhdtrwRaaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a mostly empty data frame,\n",
        "# and write it to a CSV file.\n",
        "df = pd.DataFrame(columns=['ID','followers'])\n",
        "df.to_csv('friend9.csv', index=False)\n",
        "\n",
        "# Our function\n",
        "def save_followers(fid, followers):\n",
        "    df = pd.DataFrame([[fid, followers]], columns=['ID','followers'])\n",
        "    with open('friend9.csv', 'a') as f:\n",
        "        df.to_csv(f,header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx9Zi82sRaaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crawl_followers(twitter_api, screen_name, limit=1000000, depth=2):\n",
        "    \n",
        "    # Resolve the ID for screen_name and start working with IDs for consistency\n",
        "    print(\"level 1 reciprocal friends:\")\n",
        "    seed_id = str(twitter_api.users.show(screen_name=screen_name)['id'])\n",
        "    response = make_twitter_request(t.friends.ids,\n",
        "                                user_id=seed_id, count = 5000)\n",
        "    friends = response[\"ids\"]\n",
        "    # Getting followers' ids\n",
        "    response = make_twitter_request(t.followers.ids,\n",
        "                                user_id=seed_id, count = 5000)\n",
        "    followers = response[\"ids\"]\n",
        "    # Computing reciprocal friends\n",
        "    reciprocal_friends = set(friends) & set(followers)\n",
        "    rfriends = []\n",
        "    for friend in reciprocal_friends:\n",
        "        #print(friend)\n",
        "        response = make_twitter_request(t.users.show,user_id=friend)\n",
        "        rfriends.append((response.get('id'),response.get('followers_count')))\n",
        "    rfriends.sort(key=operator.itemgetter(1),reverse=True)\n",
        "    next_queue=[x[0] for x in rfriends[:5]]\n",
        "    print(next_queue)\n",
        "    print(\"found 5 rec friends with max followers and saving it to csv\")\n",
        "    # Store a seed_id => _follower_ids mapping in MongoDB\n",
        "    save_followers(seed_id, ','.join([str(x) for x in next_queue]))\n",
        "    \n",
        "    d = 1\n",
        "    \n",
        "    while d < depth:\n",
        "        d += 1\n",
        "        \n",
        "        (queue, next_queue) = (next_queue, [])\n",
        "        # Loop through the current\n",
        "        # level of followers\n",
        "        print(\"level %d starts.\" % (d))\n",
        "        for fid in queue:\n",
        "            response = make_twitter_request(t.friends.ids,\n",
        "                                user_id=seed_id, count = 5000)\n",
        "            friends = response[\"ids\"]\n",
        "            # Getting followers' ids\n",
        "            response = make_twitter_request(t.followers.ids,\n",
        "                                user_id=seed_id, count = 5000)\n",
        "            followers = response[\"ids\"]\n",
        "            # Computing reciprocal friends\n",
        "            reciprocal_friends = set(friends) & set(followers)\n",
        "            # IDs of followers of the user with ID \"fid\"\n",
        "            rqueue = set(friends) & set(followers)\n",
        "            dfriends = []\n",
        "            for friend in reciprocal_friends:\n",
        "                #print(friend)\n",
        "                response = make_twitter_request(t.users.show,user_id=friend)\n",
        "                dfriends.append((response.get('id'),response.get('followers_count')))\n",
        "                dfriends.sort(key=operator.itemgetter(1),reverse=True)\n",
        "            rqueue=[x[0] for x in dfriends[:5]]\n",
        "            print(\"found 5 rec friends of %d with max followers and saving it to csv\" % (fid))\n",
        "            save_followers(str(fid), ','.join([str(x) for x in rqueue]))\n",
        "            # Extending the list\n",
        "            next_queue += rqueue\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF6pGUqQRaaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "screen_name=\"ZedShaw\"\n",
        "crawl_followers(t, screen_name, depth=5, limit=5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3nq4xdORaaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "G=nx.Graph()\n",
        "with open('friend9.csv','r') as csv_file:\n",
        "    csvread = csv.reader(csv_file)\n",
        "    next(csvread)\n",
        "    for line in csvread:\n",
        "        if line[0] not in G:\n",
        "            G.add_node(line[0])\n",
        "            for cnodes in line[1].split(\",\"):\n",
        "                if cnodes not in G:\n",
        "                    G.add_node(cnodes)\n",
        "                G.add_edge(line[0],cnodes)\n",
        "        else:\n",
        "            for cnodes in line[1].split(\",\"):\n",
        "                if cnodes not in G:\n",
        "                    G.add_node(cnodes)\n",
        "                G.add_edge(line[0],cnodes)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2uyiJzlRaae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nx.draw(G,node_size=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FdeCAvjRaai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_comm_3 = list(nx.community.k_clique_communities(G,3))\n",
        "k_comm_3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnnLzcPcRaak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nodelist=list(G.nodes())\n",
        "colorlist=[]\n",
        "for x in range(0,len(nodelist)):\n",
        "    colorlist.append(0.1)\n",
        "color=0.9;\n",
        "for itr in k_comm_3:\n",
        "    for i in itr:\n",
        "        colorlist[nodelist.index(i)]=color\n",
        "    color-=0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuiNKZGyRaam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nx.draw(G, node_size=200 , node_color=colorlist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXSeJXXVRaap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}